{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Article: https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02\n",
    "https://medium.com/analytics-vidhya/how-to-handle-categorical-features-ab65c3cf498e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Data and Its Types\n",
    "\n",
    "A categorical or discrete variable is one that has two or more categories (values). There are two different types of categorical variables:\n",
    "\n",
    "Nomial: A nominal variable has no intrinsic ordering to its categories. For example, gender is a categorical variable having two categories (Male and Female) with no inherent ordering between them. Another example is Country (India, Australia, America, and so forth).\n",
    "\n",
    "Ordinal: An ordinal variable has a clear ordering within its categories. For example, consider temperature as a variable with three distinct (but related) categories (low, medium, high). Another example is an education degree (Ph.D., Masterâ€™s, or Bachelorâ€™s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different Approaches to Handle Categorical Data\n",
    "\n",
    "Â· One Hot Encoding\n",
    "\n",
    "Â· One Hot Encoding with multiple categories\n",
    "\n",
    "Â· Ordinal Number Encoding\n",
    "\n",
    "Â· Count or Frequency Encoding\n",
    "\n",
    "Â· Target guided Ordinal Encoding\n",
    "\n",
    "Â· Mean Ordinal Encoding\n",
    "\n",
    "Â· Probability Ratio Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. One Hot Encoding\n",
    "\n",
    "This technique is applied for nomial categorical features.\n",
    "\n",
    "In one Hot Encoding method, each category value is converted into a new column and assigned a value as 1 or 0 to the column.\n",
    "\n",
    "This will be done using the pandas get_dummies() function and then we will drop the first column in order to avoid dummy variable trap.\n",
    "\n",
    "\n",
    "\n",
    "Advantages :\n",
    "\n",
    "Â· Simple to use and fits well for data with few categories.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Â· A high cardinality of higher categories will increase the feature space, resulting in the curse of dimensionality. (for example; high cardinal data means high number of unique values. e.g pincode is high cardinal data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. One Hot Encoding with Multiple Categories\n",
    "\n",
    "This is one of the ensemble selection techniques pick up from the KDD Orange Cup competition. In this technique, the author made a slight modification to the One hot encoding technique that is instead of creating the new column for every category, they limit creating the new column for 10 most frequent categories. Sounds like a Jargon !!!! Me too ğŸ˜Š\n",
    "\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Â· Easy to implement\n",
    "\n",
    "Â· Does not expand massively the feature space\n",
    "\n",
    "Disadvantages :\n",
    "\n",
    "Â· Does not keep track of category values that are overlooked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Ordinal Number Encoding\n",
    "\n",
    "As the name implies, this technique is used for ordinal categorical features.\n",
    "\n",
    "In this technique, each unique category value is given an integer value. For instance, â€œredâ€ equals 1, â€œgreenâ€ equals 2 and â€œblueâ€ equals 3.\n",
    "\n",
    "Domain information can be used to determine the integer value order. For example, we people love Saturday and Sundays, and most hates Monday. In this scenario the mapping for weekdays goes â€˜Mondayâ€™ is 1, â€˜Tuesdayâ€™ is 2, â€˜Wednesdayâ€™ is 3, â€˜Thursdayâ€™ is 4, â€˜Fridayâ€™ is 5,â€™Saturdayâ€™ is 6,â€™Sundayâ€™ is 7.\n",
    "\n",
    "\n",
    "Advantages :\n",
    "\n",
    "Â· Easy and straightforward to implement\n",
    "\n",
    "Â· Widely used in survey and research data encoding.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Â· Do not have a standardized interval scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Count or Frequency Encoding\n",
    "\n",
    "As the name implies, in this technique we will substitute the categories by the count of the observations that show that category in the dataset.\n",
    "\n",
    "As an example. If India appears 56 times in the country column and America appears 49 times, we replace India with 56 and America with 49 in the country column.\n",
    "\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Â· Easy to implement\n",
    "\n",
    "Â· There will be no increase in feature space.\n",
    "\n",
    "Â· Work well with the tree-based algorithms.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "It will not provide the same weight if the frequencies are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Target guided Ordinal Encoding\n",
    "\n",
    "In this technique, we will transform our categorical variable by comparing it to the target or output variable.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1) Choose a categorical variable.\n",
    "\n",
    "2) Take the aggregated mean of the categorical variable and apply it to the target variable.\n",
    "\n",
    "3) Assign higher integer values or a higher rank to the category with the highest mean.\n",
    "\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Â· Establish a monotonic relationship between the variable and the target.\n",
    "\n",
    "Â· Helps in faster learning\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Â· Because of the close relationship to the target variable, it often leads to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Mean Ordinal Encoding\n",
    "\n",
    "Itâ€™s a sight variant of target-guided ordinal encoding and is viral among data scientists. We replace the category with the obtained mean value instead of assigning integer values to it.\n",
    "\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Â· Improves classification model efficiency.\n",
    "\n",
    "Â· Fast acquisition of information\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Â· Leads to overfitting\n",
    "\n",
    "Â· May lead to possible loss of value if two categories have the same mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Probability Ratio Encoding\n",
    "\n",
    "This technique is suitable for classification problems only when the target variable is binary(Either 1 or 0 or True or False).\n",
    "\n",
    "In this technique, we will substitute the category value with the probability ratio i.e. P(1)/P(0).\n",
    "\n",
    "Steps :\n",
    "\n",
    "1) Using the categorical variable, evaluate the probability of the Target variable (where the output is True or 1).\n",
    "\n",
    "2) Calculate the probability of the Target variable having a False or 0 output.\n",
    "\n",
    "3) Calculate the probability ratio i.e. P(True or 1) / P(False or 0).\n",
    "\n",
    "4) Replace the category with a probability ratio.\n",
    "\n",
    "\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Â· Do not expand the feature space.\n",
    "\n",
    "Â· Captures information from within the category, resulting in more predictive features.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Â· Not defined when the denominator is 0.\n",
    "\n",
    "Â· It sometimes results in overfitting."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
